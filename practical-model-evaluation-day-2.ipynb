{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These notebooks are part of Kaggle’s [Practical Model Evaluation](https://www.kaggle.com/practical-model-evaluation) event, which ran from December 3-5 2019. You can find the [livestreams for this event here](https://youtu.be/7RdKnACscjA?list=PLqFaTIg4myu-HA1VGJi_7IGFkKRoZeOFt).\n",
    "\n",
    "* Day 1 Notebook: [Figuring out what matters for you](https://www.kaggle.com/rtatman/practical-model-evaluation-day-1)\n",
    "* Day 2 Notebook: [Training models with automated machine learning](https://www.kaggle.com/rtatman/practical-model-evaluation-day-2)\n",
    "* Day 3 Notebook: [Evaluating our models](https://www.kaggle.com/rtatman/practical-model-evaluation-day-3)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For today's exercise, we're going to be working on classifying roles into job titles based on information about the role. The data will be from the [2018](https://www.kaggle.com/kaggle/kaggle-survey-2018) and [2019](https://www.kaggle.com/c/kaggle-survey-2019) Kaggle data science survey. \n",
    "\n",
    "I've already [done some data cleaning](https://www.kaggle.com/rebeccaturner/data-prep-for-job-title-classification) but if you'd like to do your own or do some additional feature engineering, feel free!\n",
    "\n",
    "Today we'll be building four different models using four different libraries, including some automated machine learning libraries. \n",
    "\n",
    "> Automated machine learning (or AutoML for short) is the task of removing human labor from the process of training machine learning models. Currently most AutoML research is focused on automating model selection and hyperparameter tuning. [This video](https://www.youtube.com/watch?v=Rsg_XzgGqZw&utm_medium=notebook&utm_source=kaggle&utm_campaign=automl-event) goes into more details.\n",
    "\n",
    "The libraries we'll be using are:\n",
    "\n",
    "* [XGBoost](https://xgboost.readthedocs.io/en/latest/) (not automated machine learning: we'll be using this as a baseline)\n",
    "* [Cloud AutoML](https://cloud.google.com/automl/?utm_medium=notebook&utm_source=kaggle&utm_campaign=automl-event), an enterprise-focused automated machine learning product\n",
    "* [TPOT](https://epistasislab.github.io/tpot/), an open source automated machine learning library developed at the University of Pennsylvania\n",
    "* [H20.ai AutoML](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html), a second open source automated machine learning library developed by researchers at H20.ai\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data\n",
    "\n",
    "First let's load in our pre-cleaned data. I'll be using the 2018 data as an example and then have you work through the 2019 data as your exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "# set a seed for reproducability\n",
    "random.seed(42)\n",
    "\n",
    "# read in our data\n",
    "df_2018 = pd.read_csv(\"../input/data-prep-for-job-title-classification/data_jobs_info_2018.csv\")\n",
    "df_2019 = pd.read_csv(\"../input/data-prep-for-job-title-classification/data_jobs_info_2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analyze_and_understand_data_to_influence_product_or_business_decisions</th>\n",
       "      <th>build_a_machine_learning_service_that_operationally_improves_my_product_or_workflows</th>\n",
       "      <th>build_the_data_infrastructure_that_my_business_uses_for_storing_analyzing_and_operationalizing_data</th>\n",
       "      <th>build_prototypes_to_explore_applying_machine_learning_to_new_areas</th>\n",
       "      <th>do_research_that_advances_the_state_of_the_art_of_machine_learning</th>\n",
       "      <th>none_of_these_activities_are_an_important_part_of_my_role_at_work</th>\n",
       "      <th>what_is_the_primary_tool_that_you_use_at_work_or_school_to_analyze_data</th>\n",
       "      <th>google_cloud_platform_gcp</th>\n",
       "      <th>amazon_web_services_aws</th>\n",
       "      <th>microsoft_azure</th>\n",
       "      <th>...</th>\n",
       "      <th>time_series_data</th>\n",
       "      <th>video_data</th>\n",
       "      <th>highest_level_of_formal_education</th>\n",
       "      <th>job_title</th>\n",
       "      <th>current_industry</th>\n",
       "      <th>years_of_experience</th>\n",
       "      <th>yearly_compensation</th>\n",
       "      <th>does_your_current_employer_incorporate_machine_learning_methods_into_their_business</th>\n",
       "      <th>which_ml_library_have_you_used_the_most_selected_choice</th>\n",
       "      <th>what_percent_of_your_time_at_work_is_spent_actively_coding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyze and understand data to influence produ...</td>\n",
       "      <td>Build and/or run a machine learning service th...</td>\n",
       "      <td>Build and/or run the data infrastructure that ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Do research that advances the state of the art...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cloud-based data software &amp; APIs (AWS, GCP, Az...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Microsoft Azure</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Doctoral degree</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0% of my time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analyze and understand data to influence produ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Local or hosted development environments (RStu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Time Series Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Master’s degree</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>I am a student</td>\n",
       "      <td>0-1</td>\n",
       "      <td>0-10,000</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75% to 99% of my time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Advanced statistical software (SPSS, SAS, etc.)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Microsoft Azure</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Master’s degree</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>I am a student</td>\n",
       "      <td>0-1</td>\n",
       "      <td>0-10,000</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75% to 99% of my time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analyze and understand data to influence produ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Build prototypes to explore applying machine l...</td>\n",
       "      <td>Do research that advances the state of the art...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Local or hosted development environments (RStu...</td>\n",
       "      <td>Google Cloud Platform (GCP)</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Time Series Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor’s degree</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Computers/Technology</td>\n",
       "      <td>0-1</td>\n",
       "      <td>I do not wish to disclose my approximate yearl...</td>\n",
       "      <td>We are exploring ML methods (and may one day p...</td>\n",
       "      <td>Keras</td>\n",
       "      <td>50% to 74% of my time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Build and/or run a machine learning service th...</td>\n",
       "      <td>Build and/or run the data infrastructure that ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Local or hosted development environments (RStu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amazon Web Services (AWS)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Time Series Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Master’s degree</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Online Service/Internet-based Services</td>\n",
       "      <td>3-4</td>\n",
       "      <td>20-30,000</td>\n",
       "      <td>We have well established ML methods (i.e., mod...</td>\n",
       "      <td>Scikit-Learn</td>\n",
       "      <td>75% to 99% of my time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  analyze_and_understand_data_to_influence_product_or_business_decisions  \\\n",
       "0  Analyze and understand data to influence produ...                       \n",
       "1  Analyze and understand data to influence produ...                       \n",
       "2                                                NaN                       \n",
       "3  Analyze and understand data to influence produ...                       \n",
       "4                                                NaN                       \n",
       "\n",
       "  build_a_machine_learning_service_that_operationally_improves_my_product_or_workflows  \\\n",
       "0  Build and/or run a machine learning service th...                                     \n",
       "1                                                NaN                                     \n",
       "2                                                NaN                                     \n",
       "3                                                NaN                                     \n",
       "4  Build and/or run a machine learning service th...                                     \n",
       "\n",
       "  build_the_data_infrastructure_that_my_business_uses_for_storing_analyzing_and_operationalizing_data  \\\n",
       "0  Build and/or run the data infrastructure that ...                                                    \n",
       "1                                                NaN                                                    \n",
       "2                                                NaN                                                    \n",
       "3                                                NaN                                                    \n",
       "4  Build and/or run the data infrastructure that ...                                                    \n",
       "\n",
       "  build_prototypes_to_explore_applying_machine_learning_to_new_areas  \\\n",
       "0                                                NaN                   \n",
       "1                                                NaN                   \n",
       "2                                                NaN                   \n",
       "3  Build prototypes to explore applying machine l...                   \n",
       "4                                                NaN                   \n",
       "\n",
       "  do_research_that_advances_the_state_of_the_art_of_machine_learning  \\\n",
       "0  Do research that advances the state of the art...                   \n",
       "1                                                NaN                   \n",
       "2                                                NaN                   \n",
       "3  Do research that advances the state of the art...                   \n",
       "4                                                NaN                   \n",
       "\n",
       "  none_of_these_activities_are_an_important_part_of_my_role_at_work  \\\n",
       "0                                                NaN                  \n",
       "1                                                NaN                  \n",
       "2                                                NaN                  \n",
       "3                                                NaN                  \n",
       "4                                                NaN                  \n",
       "\n",
       "  what_is_the_primary_tool_that_you_use_at_work_or_school_to_analyze_data  \\\n",
       "0  Cloud-based data software & APIs (AWS, GCP, Az...                        \n",
       "1  Local or hosted development environments (RStu...                        \n",
       "2    Advanced statistical software (SPSS, SAS, etc.)                        \n",
       "3  Local or hosted development environments (RStu...                        \n",
       "4  Local or hosted development environments (RStu...                        \n",
       "\n",
       "     google_cloud_platform_gcp    amazon_web_services_aws  microsoft_azure  \\\n",
       "0                          NaN                        NaN  Microsoft Azure   \n",
       "1                          NaN                        NaN              NaN   \n",
       "2                          NaN                        NaN  Microsoft Azure   \n",
       "3  Google Cloud Platform (GCP)  Amazon Web Services (AWS)              NaN   \n",
       "4                          NaN  Amazon Web Services (AWS)              NaN   \n",
       "\n",
       "   ...  time_series_data video_data highest_level_of_formal_education  \\\n",
       "0  ...               NaN        NaN                   Doctoral degree   \n",
       "1  ...  Time Series Data        NaN                   Master’s degree   \n",
       "2  ...               NaN        NaN                   Master’s degree   \n",
       "3  ...  Time Series Data        NaN                 Bachelor’s degree   \n",
       "4  ...  Time Series Data        NaN                   Master’s degree   \n",
       "\n",
       "           job_title                        current_industry  \\\n",
       "0         Consultant                                   Other   \n",
       "1     Data Scientist                          I am a student   \n",
       "2       Data Analyst                          I am a student   \n",
       "3     Data Scientist                    Computers/Technology   \n",
       "4  Software Engineer  Online Service/Internet-based Services   \n",
       "\n",
       "  years_of_experience                                yearly_compensation  \\\n",
       "0                 NaN                                                NaN   \n",
       "1                 0-1                                           0-10,000   \n",
       "2                 0-1                                           0-10,000   \n",
       "3                 0-1  I do not wish to disclose my approximate yearl...   \n",
       "4                 3-4                                          20-30,000   \n",
       "\n",
       "  does_your_current_employer_incorporate_machine_learning_methods_into_their_business  \\\n",
       "0                                      I do not know                                    \n",
       "1                                      I do not know                                    \n",
       "2                                      I do not know                                    \n",
       "3  We are exploring ML methods (and may one day p...                                    \n",
       "4  We have well established ML methods (i.e., mod...                                    \n",
       "\n",
       "  which_ml_library_have_you_used_the_most_selected_choice  \\\n",
       "0                                                NaN        \n",
       "1                                                NaN        \n",
       "2                                                NaN        \n",
       "3                                              Keras        \n",
       "4                                       Scikit-Learn        \n",
       "\n",
       "  what_percent_of_your_time_at_work_is_spent_actively_coding  \n",
       "0                                      0% of my time          \n",
       "1                              75% to 99% of my time          \n",
       "2                              75% to 99% of my time          \n",
       "3                              50% to 74% of my time          \n",
       "4                              75% to 99% of my time          \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analyze_and_understand_data_to_influence_product_or_business_decisions</th>\n",
       "      <th>build_the_data_infrastructure_that_my_business_uses_for_storing_analyzing_and_operationalizing_data</th>\n",
       "      <th>build_prototypes_to_explore_applying_machine_learning_to_new_areas</th>\n",
       "      <th>build_a_machine_learning_service_that_operationally_improves_my_product_or_workflows</th>\n",
       "      <th>experimentation_and_iteration_to_improve_existing_ml_models</th>\n",
       "      <th>do_research_that_advances_the_state_of_the_art_of_machine_learning</th>\n",
       "      <th>none_of_these_activities_are_an_important_part_of_my_role_at_work</th>\n",
       "      <th>what_is_the_primary_tool_that_you_use_at_work_or_school_to_analyze_data</th>\n",
       "      <th>highest_level_of_formal_education</th>\n",
       "      <th>job_title</th>\n",
       "      <th>yearly_compensation</th>\n",
       "      <th>does_your_current_employer_incorporate_machine_learning_methods_into_their_business</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Basic statistical software (Microsoft Excel, G...</td>\n",
       "      <td>Master’s degree</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>30,000-39,999</td>\n",
       "      <td>I do not know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analyze and understand data to influence produ...</td>\n",
       "      <td>Build and/or run the data infrastructure that ...</td>\n",
       "      <td>Build prototypes to explore applying machine l...</td>\n",
       "      <td>Build and/or run a machine learning service th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cloud-based data software &amp; APIs (AWS, GCP, Az...</td>\n",
       "      <td>Professional degree</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>5,000-7,499</td>\n",
       "      <td>We have well established ML methods (i.e., mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Build prototypes to explore applying machine l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Do research that advances the state of the art...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Advanced statistical software (SPSS, SAS, etc.)</td>\n",
       "      <td>Master’s degree</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>60,000-69,999</td>\n",
       "      <td>We have well established ML methods (i.e., mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analyze and understand data to influence produ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Experimentation and iteration to improve exist...</td>\n",
       "      <td>Do research that advances the state of the art...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Local development environments (RStudio, Jupyt...</td>\n",
       "      <td>Master’s degree</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>10,000-14,999</td>\n",
       "      <td>We are exploring ML methods (and may one day p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Analyze and understand data to influence produ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Build prototypes to explore applying machine l...</td>\n",
       "      <td>Build and/or run a machine learning service th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Local development environments (RStudio, Jupyt...</td>\n",
       "      <td>Bachelor’s degree</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>80,000-89,999</td>\n",
       "      <td>We recently started using ML methods (i.e., mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  analyze_and_understand_data_to_influence_product_or_business_decisions  \\\n",
       "0                                                NaN                       \n",
       "1  Analyze and understand data to influence produ...                       \n",
       "2                                                NaN                       \n",
       "3  Analyze and understand data to influence produ...                       \n",
       "4  Analyze and understand data to influence produ...                       \n",
       "\n",
       "  build_the_data_infrastructure_that_my_business_uses_for_storing_analyzing_and_operationalizing_data  \\\n",
       "0                                                NaN                                                    \n",
       "1  Build and/or run the data infrastructure that ...                                                    \n",
       "2                                                NaN                                                    \n",
       "3                                                NaN                                                    \n",
       "4                                                NaN                                                    \n",
       "\n",
       "  build_prototypes_to_explore_applying_machine_learning_to_new_areas  \\\n",
       "0                                                NaN                   \n",
       "1  Build prototypes to explore applying machine l...                   \n",
       "2  Build prototypes to explore applying machine l...                   \n",
       "3                                                NaN                   \n",
       "4  Build prototypes to explore applying machine l...                   \n",
       "\n",
       "  build_a_machine_learning_service_that_operationally_improves_my_product_or_workflows  \\\n",
       "0                                                NaN                                     \n",
       "1  Build and/or run a machine learning service th...                                     \n",
       "2                                                NaN                                     \n",
       "3                                                NaN                                     \n",
       "4  Build and/or run a machine learning service th...                                     \n",
       "\n",
       "  experimentation_and_iteration_to_improve_existing_ml_models  \\\n",
       "0                                                NaN            \n",
       "1                                                NaN            \n",
       "2                                                NaN            \n",
       "3  Experimentation and iteration to improve exist...            \n",
       "4                                                NaN            \n",
       "\n",
       "  do_research_that_advances_the_state_of_the_art_of_machine_learning  \\\n",
       "0                                                NaN                   \n",
       "1                                                NaN                   \n",
       "2  Do research that advances the state of the art...                   \n",
       "3  Do research that advances the state of the art...                   \n",
       "4                                                NaN                   \n",
       "\n",
       "  none_of_these_activities_are_an_important_part_of_my_role_at_work  \\\n",
       "0                                                NaN                  \n",
       "1                                                NaN                  \n",
       "2                                                NaN                  \n",
       "3                                                NaN                  \n",
       "4                                                NaN                  \n",
       "\n",
       "  what_is_the_primary_tool_that_you_use_at_work_or_school_to_analyze_data  \\\n",
       "0  Basic statistical software (Microsoft Excel, G...                        \n",
       "1  Cloud-based data software & APIs (AWS, GCP, Az...                        \n",
       "2    Advanced statistical software (SPSS, SAS, etc.)                        \n",
       "3  Local development environments (RStudio, Jupyt...                        \n",
       "4  Local development environments (RStudio, Jupyt...                        \n",
       "\n",
       "  highest_level_of_formal_education          job_title yearly_compensation  \\\n",
       "0                   Master’s degree  Software Engineer       30,000-39,999   \n",
       "1               Professional degree  Software Engineer         5,000-7,499   \n",
       "2                   Master’s degree     Data Scientist       60,000-69,999   \n",
       "3                   Master’s degree     Data Scientist       10,000-14,999   \n",
       "4                 Bachelor’s degree     Data Scientist       80,000-89,999   \n",
       "\n",
       "  does_your_current_employer_incorporate_machine_learning_methods_into_their_business  \n",
       "0                                      I do not know                                   \n",
       "1  We have well established ML methods (i.e., mod...                                   \n",
       "2  We have well established ML methods (i.e., mod...                                   \n",
       "3  We are exploring ML methods (and may one day p...                                   \n",
       "4  We recently started using ML methods (i.e., mo...                                   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2019.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "We do have an additional step of preperation. First, we'll split into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into predictor & target variables\n",
    "X = df_2018.drop(\"job_title\", axis=1)\n",
    "y = df_2018[\"job_title\"]\n",
    "\n",
    "# Splitting data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, test_size=0.20)\n",
    "\n",
    "# save out the split training data to use with Cloud AutoML\n",
    "with open(\"train_data_2018.csv\", \"+w\") as file:\n",
    "    pd.concat([X_train, y_train], axis=1).to_csv(file, index=False)\n",
    "with open(\"test_data_2018.csv\", \"+w\") as file:\n",
    "    pd.concat([X_test, y_test], axis=1).to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For H20 AutoML and Cloud AutoML we don't need to do anything else. (Actually for Cloud AutoML we don't even need to split our data, but we'll look at that in a minute.) \n",
    "\n",
    "For TPOT and XGBoost, however, we need to make sure that all our input data is numeric. We'll be using [ordinal label encoding](https://contrib.scikit-learn.org/categorical-encoding/ordinal.html) for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode all features using ordinal encoding\n",
    "encoder_x = ce.OrdinalEncoder()\n",
    "X_encoded = encoder_x.fit_transform(X)\n",
    "\n",
    "# you'll need to use a different encoder for each dataframe\n",
    "encoder_y = ce.OrdinalEncoder()\n",
    "y_encoded = encoder_y.fit_transform(y)\n",
    "\n",
    "# split encoded dataset\n",
    "X_train_encoded, X_test_encoded, y_train_encoded, y_test_encoded = train_test_split(X_encoded, y_encoded,\n",
    "                                                    train_size=0.80, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Baseline\n",
    "\n",
    "First, we're going to train a basic XGBoost model using the default arguments. We cover XGBoost in more detail in the [Intro To Machine Learning course](https://www.kaggle.com/learn/intro-to-machine-learning), so I'm not going to talk about it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# train XGBoost model with default parameters\n",
    "my_model = XGBClassifier()\n",
    "my_model.fit(X_train_encoded, y_train_encoded, verbose=False)\n",
    "\n",
    "# and save our model\n",
    "my_model.save_model(\"xgboost_baseline.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 2, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud AutoML\n",
    "\n",
    "Now let's train our Cloud AutoML model! We'll be using both the GCP console and notebook code here, so you'll probably want to open those in separate tabs or windows.\n",
    "\n",
    "### Prepare your account and project\n",
    "\n",
    "\n",
    "* First you’ll need to [create a GCP account](https://accounts.google.com/signup/v2/webcreateaccount?service=cloudconsole&continue=https%3A%2F%2Fconsole.cloud.google.com%2F&dsh=S-385463669%3A1575309184770524&gmb=exp&biz=false&flowName=GlifWebSignIn&flowEntry=SignUp&nogm=true&utm_medium=notebook&utm_source=kaggle&utm_campaign=automl-event) (if you already have a Google account you can use that one) and [enable billing](https://www.youtube.com/watch?v=uINleRduCWM&utm_medium=notebook&utm_source=kaggle&utm_campaign=automl-event).\n",
    "\n",
    "\n",
    "> For now, you do need to have a credit card in order to enable billing and you need billing enabled to use Cloud AutoML. If you’re not able to enable billing you can still follow along with the rest of the workshop, just skip the Cloud AutoML parts. \n",
    "\n",
    " \n",
    "\n",
    "* From there, [create a new project](https://cloud.google.com/appengine/docs/standard/nodejs/building-app/creating-project?utm_medium=notebook&utm_source=kaggle&utm_campaign=automl-event). You should [set the region of your project](https://cloud.google.com/compute/docs/regions-zones/?utm_medium=notebook&utm_source=kaggle&utm_campaign=automl-event) to “us-central1”.\n",
    "\n",
    "* Go to the [AutoML Tables](https://console.cloud.google.com/automl-tables?utm_medium=notebook&utm_source=kaggle&utm_campaign=automl-event) page in the Google Cloud Console and click *enable API*. This will let you train an AutoML Tables model in your current project. \n",
    "\n",
    "\n",
    "### Creating your dataset\n",
    "\n",
    "\n",
    "For this workshop, we’re going to create our AutoML datasets using the GCP console. The reason for this is that importing datasets can take a while. If you have the code in your notebook to import your dataset right before the code to create your model, when you run your notebook top to bottom it’ll give you an error because the modelling code was run before the dataset was done importing.\n",
    "\n",
    "\n",
    "* Click on “Datasets” in the list on the left hand side of your screen and then click on the blue **[+] New Dataset** text near the top of your screen.\n",
    "\n",
    "* Give your dataset a name and make sure the region is **US-CENTRAL1**.  \n",
    "\n",
    "* Select “Upload files from your computer” and select the file with the dataset you want. \n",
    "\n",
    "* Click on **BROWSE** under the “Select Files” button and a side panel will pop up. \n",
    "\n",
    "    * If you haven’t created any buckets you’ll see the text “No buckets found”. To create a new bucket, click on the icon that looks like a shopping basket with a plus sign in it.\n",
    "\n",
    "    * Follow the prompts to create your bucket. **Important:** Make sure in the “Choose where to store your data” step, you pick “Region” and set the location as “us-central1 (Iowa). \n",
    "\n",
    "* Select the bucket where you’d like to store your data.\n",
    "\n",
    "* Import your dataset. (This may take a while.)\n",
    "\n",
    "* Once your dataset is done importing, take a close look at your imported data and make sure it looks the way you’d expect.\n",
    "\n",
    "\n",
    "### Training our model\n",
    "\n",
    "\n",
    "In order to train an AutoML model from inside Kaggle Notebooks, you’ll need to attach a notebook to your Google Cloud Account. [This video goes into more detail](https://youtu.be/xP99eh6nQN0?utm_medium=notebook&utm_source=kaggle&utm_campaign=automl-event). \n",
    "\n",
    "\n",
    "Then you can modify the following code to start your AutoML model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "from google.cloud import automl_v1beta1 as automl\n",
    "from kaggle.gcp import KaggleKernelCredentials\n",
    "from kaggle_secrets import GcpTarget\n",
    "from google.cloud import storage\n",
    "\n",
    "# don't change this value!\n",
    "REGION = 'us-central1' # don't change: this is the only region that works currently\n",
    "\n",
    "# these you'll change based on your GCP project/data\n",
    "PROJECT_ID = 'gm-kaggle-1' # this will come from your specific GCP project\n",
    "DATASET_DISPLAY_NAME = 'dataset_job_2018_1575641833179' # name of your uploaded dataset (from GCP console)\n",
    "TARGET_COLUMN = 'job_title' # column with feature you're trying to predict\n",
    "\n",
    "# these can be whatever you like\n",
    "MODEL_DISPLAY_NAME = 'kaggle_automl_example_model1' # what you want to call your model\n",
    "TRAIN_BUDGET = 1000 # max time to train model in milli-hours, from 1000-72000\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT_ID, credentials=KaggleKernelCredentials(GcpTarget.GCS)) \n",
    "tables_gcs_client = automl.GcsClient(client=storage_client, credentials=KaggleKernelCredentials(GcpTarget.GCS)) \n",
    "tables_client = automl.TablesClient(project=PROJECT_ID, region=REGION, gcs_client=tables_gcs_client, credentials=KaggleKernelCredentials(GcpTarget.AUTOML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/203368842829/locations/us-central1/datasets/TBL8951920208142925824\"\n",
       "display_name: \"dataset_job_2018_1575641833179\"\n",
       "create_time {\n",
       "  seconds: 1575641967\n",
       "  nanos: 606150000\n",
       "}\n",
       "etag: \"AB3BwFrI6B3z5FzG6Ho_PSl4SgwhYbZS23eIPj7JjcK1pt0AQ-4cH_OxqdigVQTzmro=\"\n",
       "example_count: 13862\n",
       "tables_dataset_metadata {\n",
       "  primary_table_spec_id: \"8306722386917457920\"\n",
       "  target_column_spec_id: \"731362149447761920\"\n",
       "  target_column_correlations {\n",
       "    key: \"1019592525599473664\"\n",
       "    value {\n",
       "      cramers_v: 0.01589312144662912\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"1307822901751185408\"\n",
       "    value {\n",
       "      cramers_v: 0.026228333569284504\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"154901397144338432\"\n",
       "    value {\n",
       "      cramers_v: 0.010363774712942754\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"1596053277902897152\"\n",
       "    value {\n",
       "      cramers_v: 0.03745949678439566\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"2172514030206320640\"\n",
       "    value {\n",
       "      cramers_v: 0.026341049526701677\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"2460744406358032384\"\n",
       "    value {\n",
       "      cramers_v: 0.01480733951023409\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"2748974782509744128\"\n",
       "    value {\n",
       "      cramers_v: 0.02990491323748493\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"3037205158661455872\"\n",
       "    value {\n",
       "      cramers_v: 0.01498704796962198\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"3325435534813167616\"\n",
       "    value {\n",
       "      cramers_v: 0.015452905323776783\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"3613665910964879360\"\n",
       "    value {\n",
       "      cramers_v: 0.027984289925978578\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"3901896287116591104\"\n",
       "    value {\n",
       "      cramers_v: 0.05960229203419279\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"4190126663268302848\"\n",
       "    value {\n",
       "      cramers_v: 0.05767843611880267\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"4334241851344158720\"\n",
       "    value {\n",
       "      cramers_v: 0.02994046048864575\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"443131773296050176\"\n",
       "    value {\n",
       "      cramers_v: 0.045443076652998474\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"4766587415571726336\"\n",
       "    value {\n",
       "      cramers_v: 0.014786091207045335\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"5054817791723438080\"\n",
       "    value {\n",
       "      cramers_v: 0.05018032475021056\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"5631278544026861568\"\n",
       "    value {\n",
       "      cramers_v: 0.005501737941815892\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"5919508920178573312\"\n",
       "    value {\n",
       "      cramers_v: 0.015852384216764638\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"6207739296330285056\"\n",
       "    value {\n",
       "      cramers_v: 0.05113002137364722\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"6495969672481996800\"\n",
       "    value {\n",
       "      cramers_v: 0.051269547098965126\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"6640084860557852672\"\n",
       "    value {\n",
       "      cramers_v: 0.011611357384300698\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"7072430424785420288\"\n",
       "    value {\n",
       "      cramers_v: 0.028350032525972412\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"7360660800937132032\"\n",
       "    value {\n",
       "      cramers_v: 0.04437117282601206\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"7648891177088843776\"\n",
       "    value {\n",
       "      cramers_v: 0.03955251126873317\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"7937121553240555520\"\n",
       "    value {\n",
       "      cramers_v: 0.010360098755500056\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"8225351929392267264\"\n",
       "    value {\n",
       "      cramers_v: 0.06747656791128931\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"8513582305543979008\"\n",
       "    value {\n",
       "      cramers_v: 0.026584870607957077\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"8801812681695690752\"\n",
       "    value {\n",
       "      cramers_v: 0.05075928994622323\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"8945927869771546624\"\n",
       "    value {\n",
       "      cramers_v: 0.028212902090680007\n",
       "    }\n",
       "  }\n",
       "  stats_update_time {\n",
       "    seconds: 1575650891\n",
       "    nanos: 478000000\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first you'll need to make sure your model is predicting the right column\n",
    "tables_client.set_target_column(\n",
    "    dataset_display_name=DATASET_DISPLAY_NAME,\n",
    "    column_spec_display_name=TARGET_COLUMN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let our model know that input columns may have missing values\n",
    "for col in tables_client.list_column_specs(project=PROJECT_ID,\n",
    "                                           dataset_display_name=DATASET_DISPLAY_NAME):\n",
    "    if TARGET_COLUMN in col.display_name:\n",
    "        continue\n",
    "    tables_client.update_column_spec(project=PROJECT_ID,\n",
    "                                     dataset_display_name=DATASET_DISPLAY_NAME,\n",
    "                                     column_spec_display_name=col.display_name,\n",
    "                                     nullable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and then you'll need to kick off your model training\n",
    "response = tables_client.create_model(MODEL_DISPLAY_NAME, dataset_display_name=DATASET_DISPLAY_NAME, \n",
    "                                      train_budget_milli_node_hours=TRAIN_BUDGET, \n",
    "                                      exclude_column_spec_names=[TARGET_COLUMN])\n",
    "\n",
    "# check if it's done yet (it won't be)\n",
    "response.done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our model starts training, we don't need to do anything else: it's already saved in our GCP account and good to go for tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOT\n",
    "\n",
    "Alright, now we'll move onto [TPOT](https://epistasislab.github.io/tpot/). This is an academic library built on top of scikit-learn, and my favorite thing about it is that when you export a model you're actually exporting all the Python code you need to train that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "347196bf-81e7-4114-8394-619a61278993",
    "_uuid": "e19d70b16755f4d338e27f17d4320dacf1fd9628",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a8fe5c3beb46018165b95a814fa7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=180, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.4935508049607237\n",
      "\r\n",
      "The optimized pipeline was not improved after evaluating 2 more generations. Will end the optimization process.\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\r\n",
      "Best pipeline: XGBClassifier(input_matrix, learning_rate=0.1, max_depth=10, min_child_weight=16, n_estimators=100, nthread=1, subsample=0.3)\n",
      "import numpy as np\r\n",
      "import pandas as pd\r\n",
      "from sklearn.model_selection import train_test_split\r\n",
      "from xgboost import XGBClassifier\r\n",
      "\r\n",
      "# NOTE: Make sure that the class is labeled 'target' in the data file\r\n",
      "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\r\n",
      "features = tpot_data.drop('target', axis=1).values\r\n",
      "training_features, testing_features, training_target, testing_target = \\\r\n",
      "            train_test_split(features, tpot_data['target'].values, random_state=None)\r\n",
      "\r\n",
      "# Average CV score on the training set was:0.4935508049607237\r\n",
      "exported_pipeline = XGBClassifier(learning_rate=0.1, max_depth=10, min_child_weight=16, n_estimators=100, nthread=1, subsample=0.3)\r\n",
      "\r\n",
      "exported_pipeline.fit(training_features, training_target)\r\n",
      "results = exported_pipeline.predict(testing_features)\r\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "# create & fit TPOT classifier with \n",
    "tpot = TPOTClassifier(generations=8, population_size=20, \n",
    "                      verbosity=2, early_stop=2)\n",
    "tpot.fit(X_train_encoded, y_train_encoded)\n",
    "\n",
    "# save our model code\n",
    "tpot.export('tpot_pipeline.py')\n",
    "\n",
    "# print the model code to see what it says\n",
    "!cat tpot_pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H20.ai AutoML\n",
    "\n",
    "For our final model we'll be using [H20.ai's open source AutoML library](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html). One thing that I like about this library is that, as each model is trained, its evaluated both on its own and as part of a stacked ensemble. Kaggle competitors are very fond of stacking (and H20 is known for hiring a lot of top Kagglers) so it's nice to have that automated for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_232\"; OpenJDK Runtime Environment (build 1.8.0_232-8u232-b09-1~deb9u1-b09); OpenJDK 64-Bit Server VM (build 25.232-b09, mixed mode)\n",
      "  Starting server from /opt/conda/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmp9ui_h8_c\n",
      "  JVM stdout: /tmp/tmp9ui_h8_c/h2o_unknownUser_started_from_python.out\n",
      "  JVM stderr: /tmp/tmp9ui_h8_c/h2o_unknownUser_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.26.0.8</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month and 19 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_unknownUser_zf7t8t</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>{'http': None, 'https': None}</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       Etc/UTC\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.26.0.8\n",
       "H2O cluster version age:    1 month and 19 days\n",
       "H2O cluster name:           H2O_from_python_unknownUser_zf7t8t\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:       {'http': None, 'https': None}\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python version:             3.6.6 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# initilaize an H20 instance running locally\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# convert our data to h20Frame, an alternative to pandas datatables\n",
    "train_data = h2o.H2OFrame(X_train)\n",
    "test_data = h2o.H2OFrame(list(y_train))\n",
    "\n",
    "train_data = train_data.cbind(test_data)\n",
    "\n",
    "# Run AutoML for 20 base models (limited to 1 hour max runtime by default)\n",
    "aml = H2OAutoML(max_models=20, seed=1)\n",
    "aml.train(y=\"C1\", training_frame=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                 </th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GLM_grid_1_AutoML_20191207_112852_model_1</td><td style=\"text-align: right;\">              0.678643</td><td style=\"text-align: right;\">  1.4374 </td><td style=\"text-align: right;\">0.695061</td><td style=\"text-align: right;\">0.48311 </td></tr>\n",
       "<tr><td>XGBoost_1_AutoML_20191207_112852         </td><td style=\"text-align: right;\">              0.682858</td><td style=\"text-align: right;\">  1.44783</td><td style=\"text-align: right;\">0.700149</td><td style=\"text-align: right;\">0.490208</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20191207_112852             </td><td style=\"text-align: right;\">              0.684204</td><td style=\"text-align: right;\">  1.47622</td><td style=\"text-align: right;\">0.695915</td><td style=\"text-align: right;\">0.484297</td></tr>\n",
       "<tr><td>XGBoost_2_AutoML_20191207_112852         </td><td style=\"text-align: right;\">              0.686176</td><td style=\"text-align: right;\">  1.45283</td><td style=\"text-align: right;\">0.702352</td><td style=\"text-align: right;\">0.493299</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20191207_112852             </td><td style=\"text-align: right;\">              0.688342</td><td style=\"text-align: right;\">  1.49487</td><td style=\"text-align: right;\">0.696846</td><td style=\"text-align: right;\">0.485595</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the top five models from the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "lb.head(rows=5)\n",
    "\n",
    "# The leader model can be access with `aml.leader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/GLM_grid_1_AutoML_20191207_112852_model_1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model out (we'll need to for tomorrow!)\n",
    "h2o.save_model(aml.leader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that we've saved each of our models\n",
    "\n",
    "Before we wrap up for the day, we want to make sure we've saved all of our models for tomorrow! The Cloud AutoML model is saved automatically on GCP, but we've saved each of the other models in our current working directory. Let's just double check that that's the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLM_grid_1_AutoML_20191207_112852_model_1  tpot_pipeline.py\r\n",
      "__notebook__.ipynb\t\t\t   train_data_2018.csv\r\n",
      "__output__.json\t\t\t\t   xgboost_baseline.model\r\n",
      "test_data_2018.csv\r\n"
     ]
    }
   ],
   "source": [
    "# check to see that we've saved all of our models\n",
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we've got three models and the code for the notebook. We're all set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Now it's your turn! Following the steps above, use the `df_2019` dataframe and: \n",
    "\n",
    "* Prepare your data (split into testing and training, encode variables)\n",
    "* Train your models: XGBoost, Cloud AutoML, TPOT and H20 AutoML\n",
    "\n",
    "> Note: if you can't or would prefer not to set up billing on order to use Cloud AutoML, feel free to skip training that model.\n",
    "\n",
    "* Remember to save your models! You'll need them tomorrow and, since it takes a while to run AutoML code, you don't want to have to run it multiple times.\n",
    "\n",
    "Have fun training your models and I'll see you all tomorrow for our final model evaluation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "05a8fe5c3beb46018165b95a814fa7a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6e1cf06a6f334df8bc238c8a4f948a95",
        "IPY_MODEL_0641f7b21a4e4704939e05550a3e4a22"
       ],
       "layout": "IPY_MODEL_05c85d44f83e419c8f8848af32038cc4"
      }
     },
     "05c85d44f83e419c8f8848af32038cc4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0641f7b21a4e4704939e05550a3e4a22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6530d1bea0754a6fbb2378f124e45bcd",
       "placeholder": "​",
       "style": "IPY_MODEL_c2d98c0dfb024ea99e69856d968e5067",
       "value": " 40/180 [29:05&lt;1:30:17, 38.70s/pipeline]"
      }
     },
     "3d62dade18964b64bb7651ebab22fdc1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "6530d1bea0754a6fbb2378f124e45bcd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e1cf06a6f334df8bc238c8a4f948a95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "Optimization Progress:  22%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_87ae3c7fc7d949578f89726665fcbed1",
       "max": 180,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3d62dade18964b64bb7651ebab22fdc1",
       "value": 40
      }
     },
     "87ae3c7fc7d949578f89726665fcbed1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c2d98c0dfb024ea99e69856d968e5067": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
